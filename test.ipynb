{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, metrics, svm\n",
    "from IPython.display import Image\n",
    "import warnings\n",
    "from collections import namedtuple\n",
    "import gzip\n",
    "import logging\n",
    "from importlib import reload\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.INFO, datefmt='%H:%M:%S')\n",
    "import base64\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DocItem = namedtuple('DocItem', ['doc_id', 'is_spam', 'url', 'words'])\n",
    "\n",
    "def trace(items_num, trace_num=1000):\n",
    "    if items_num % trace_num == 0: logging.info(\"Complete items %05d\" % items_num)\n",
    "\n",
    "def load_csv(input_file_name):    \n",
    "    \n",
    "    with gzip.open(input_file_name) if input_file_name.endswith('gz') else open(input_file_name)  as input_file:            \n",
    "        headers = input_file.readline()\n",
    "        \n",
    "        for i, line in enumerate(input_file):\n",
    "            trace(i)\n",
    "            line = line.decode()\n",
    "            parts = line.strip().split('\\t')\n",
    "            url_id = int(parts[0])                                        \n",
    "            mark = bool(int(parts[1]))                    \n",
    "            url = parts[2]\n",
    "            pageInb64 = parts[3]\n",
    "            html_data = base64.b64decode(pageInb64).decode(\"utf-8\", errors=\"ignore\")\n",
    "            yield DocItem(url_id, mark, url, html_data)            \n",
    "                \n",
    "        trace(i, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:00:30 INFO:Complete items 00000\n",
      "20:00:32 INFO:Complete items 01000\n",
      "20:00:33 INFO:Complete items 02000\n",
      "20:00:34 INFO:Complete items 03000\n",
      "20:00:35 INFO:Complete items 04000\n",
      "20:00:36 INFO:Complete items 05000\n",
      "20:00:36 INFO:Complete items 06000\n",
      "20:00:38 INFO:Complete items 07000\n",
      "20:00:38 INFO:Complete items 07043\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_FILE = 'kaggle_train_data_tab_new.csv.gz'\n",
    "train_docs = list(load_csv(TRAIN_DATA_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(train_docs)\n",
    "train_data.head()\n",
    "X_train = train_data['words']\n",
    "y_train = train_data['is_spam'].replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7044, 13692), (7044,))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = TfidfVectorizer(ngram_range=(2,2), min_df=0.01, sublinear_tf=True)\n",
    "X_train = tf.fit_transform(X_train)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.40012305\n",
      "Iteration 2, loss = 0.12983386\n",
      "Iteration 3, loss = 0.07720951\n",
      "Iteration 4, loss = 0.05596109\n",
      "Iteration 5, loss = 0.04313051\n",
      "Iteration 6, loss = 0.03354300\n",
      "Iteration 7, loss = 0.02678482\n",
      "Iteration 8, loss = 0.02146630\n",
      "Iteration 9, loss = 0.01710335\n",
      "Iteration 10, loss = 0.01398323\n",
      "Iteration 11, loss = 0.01176881\n",
      "Iteration 12, loss = 0.00997675\n",
      "Iteration 13, loss = 0.00852785\n",
      "Iteration 14, loss = 0.00742534\n",
      "Iteration 15, loss = 0.00675678\n",
      "Iteration 16, loss = 0.00573321\n",
      "Iteration 17, loss = 0.00505746\n",
      "Iteration 18, loss = 0.00457808\n",
      "Iteration 19, loss = 0.00418360\n",
      "Iteration 20, loss = 0.00383641\n",
      "Iteration 21, loss = 0.00355549\n",
      "Iteration 22, loss = 0.00333317\n",
      "Iteration 23, loss = 0.00314086\n",
      "Iteration 24, loss = 0.00299098\n",
      "Iteration 25, loss = 0.00281719\n",
      "Iteration 26, loss = 0.00270297\n",
      "Iteration 27, loss = 0.00260466\n",
      "Iteration 28, loss = 0.00251223\n",
      "Iteration 29, loss = 0.00240278\n",
      "Iteration 30, loss = 0.00233341\n",
      "Iteration 31, loss = 0.00226755\n",
      "Iteration 32, loss = 0.00218601\n",
      "Iteration 33, loss = 0.00213116\n",
      "Iteration 34, loss = 0.00208273\n",
      "Iteration 35, loss = 0.00204438\n",
      "Iteration 36, loss = 0.00199454\n",
      "Iteration 37, loss = 0.00195649\n",
      "Iteration 38, loss = 0.00191698\n",
      "Iteration 39, loss = 0.00187942\n",
      "Iteration 40, loss = 0.00184239\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "F1 : 0.9894%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 : 0.9775%\n",
      "-- Epoch 1\n",
      "Norm: 35.91, NNZs: 13302, Bias: 0.415871, T: 5635, Avg. loss: 0.090123\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 30.11, NNZs: 13411, Bias: 0.379324, T: 11270, Avg. loss: 0.033435\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27.85, NNZs: 13560, Bias: 0.359834, T: 16905, Avg. loss: 0.025530\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.66, NNZs: 13581, Bias: 0.336854, T: 22540, Avg. loss: 0.021999\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 26.23, NNZs: 13595, Bias: 0.333231, T: 28175, Avg. loss: 0.019985\n",
      "Total training time: 0.03 seconds.\n",
      "F1 : 0.9875%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# m = SGDClassifier(verbose=True)\n",
    "# scores = cross_val_score(m, X_train, y_train, cv=5)\n",
    "# print (scores)\n",
    "\n",
    "models = [MLPClassifier, ExtraTreesClassifier, SGDClassifier]\n",
    "f1_scores = []\n",
    "trained_models = []\n",
    "for model in models:\n",
    "    m = model(verbose=True)\n",
    "    m.fit(X_train, y_train)\n",
    "#     output = m.predict(X_test)\n",
    "#     f1 = f1_score(output, y_test)\n",
    "#     print(f'F1 : {f1:.4f}%')\n",
    "\n",
    "#     f1_scores.append(f1)\n",
    "    trained_models.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model1 = trained_models[0]\n",
    "best_model2 = trained_models[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:44:48 INFO:Complete items 00000\n",
      "21:44:51 INFO:Complete items 01000\n",
      "21:44:54 INFO:Complete items 02000\n",
      "21:44:55 INFO:Complete items 03000\n",
      "21:44:57 INFO:Complete items 04000\n",
      "21:44:59 INFO:Complete items 05000\n",
      "21:45:00 INFO:Complete items 06000\n",
      "21:45:02 INFO:Complete items 07000\n",
      "21:45:03 INFO:Complete items 08000\n",
      "21:45:05 INFO:Complete items 09000\n",
      "21:45:07 INFO:Complete items 10000\n",
      "21:45:08 INFO:Complete items 11000\n",
      "21:45:09 INFO:Complete items 12000\n",
      "21:45:10 INFO:Complete items 13000\n",
      "21:45:12 INFO:Complete items 14000\n",
      "21:45:13 INFO:Complete items 15000\n",
      "21:45:14 INFO:Complete items 16000\n",
      "21:45:14 INFO:Complete items 16038\n"
     ]
    }
   ],
   "source": [
    "TEST_DATA_FILE = 'kaggle_test_data_tab_new.csv.gz'\n",
    "test_docs = list(load_csv(TEST_DATA_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16039/16039 [03:19<00:00, 79.34it/s] \n",
      "100%|██████████| 16039/16039 [02:51<00:00, 93.31it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import csv\n",
    "with open('my_submission.csv' , 'w') as fout:\n",
    "    writer = csv.writer(fout)\n",
    "    writer.writerow(['Id','Prediction'])\n",
    "    for item in tqdm(test_docs):\n",
    "        line = item.words\n",
    "        line = tf.transform([line])\n",
    "        prediction = best_model1.predict(line)[0]\n",
    "        writer.writerow([item[0], prediction])\n",
    "        \n",
    "# with open('my_submission2.csv' , 'w') as fout:\n",
    "#     writer = csv.writer(fout)\n",
    "#     writer.writerow(['Id','Prediction'])\n",
    "#     for item in tqdm(test_docs):\n",
    "#         line = item.words\n",
    "#         line = tf.transform([line])\n",
    "#         prediction = best_model2.predict(line)[0]\n",
    "#         writer.writerow([item[0], prediction])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
